{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se trabajará con denoising autoencoder (dAE), que corresponde esencialmente a un autoencoder entrenado\n",
    "para reconstruir ejemplos parcialmente corruptos. Varios autores han demostrado que mediante esta modificación simple es posible obtener representaciones más robustas y significativas que aquellas obtenidas por un AE básico. En este documento se explorará la aplicación más \"natural\" o \"directa\" del método.\n",
    "\n",
    "***a)*** Se procede a generar artificialmente una versión corrupta de las imágenes en MNIST utilizando el siguiente modelo de ruido (masking noise): si $\\textbf{x} \\in \\mathbb{R}^d$ es una de las imágenes originales, la versión ruidosa $\\tilde{\\textbf{x}}$ se obtiene\n",
    "como $\\tilde{\\textbf{x}} = \\textbf{x} \\odot \\xi$ donde $\\odot$ denota el producto de Hadamard (componente a componente) y $\\xi \\in \\mathbb{R}^d$ es un vector aleatorio binario con componentes $\\text{Ber}(p)$ independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import binomial\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalizacion de imagenes\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Transformación en vectores R^{784}\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Creación conjunto de validación\n",
    "nval = 5000\n",
    "x_val = x_train[-nval:]\n",
    "y_val = y_train[-nval:]\n",
    "x_train = x_train[:-nval]\n",
    "y_train = y_train[:-nval]\n",
    "\n",
    "# Transformación de salidas a probabilidades de activación\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAABzCAYAAAAfb55ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2111cf8b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_level = 0.1\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_train.shape)\n",
    "noisy_x_train = x_train*noise_mask\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_val.shape)\n",
    "noisy_x_val = x_val*noise_mask\n",
    "noise_mask = binomial(n=1,p=noise_level,size=x_test.shape)\n",
    "noisy_x_test = x_test*noise_mask\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(noisy_x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***b)*** A continuación se entrena un autoencoder para reconstruir las imágenes corruptas generadas en el ítem anterior. Para evaluar la calidad de la reconstrucción se utilizará el mismo error de reconstrucción de la sección *3.1* y se evaluará cualitativamente por medio de la visualización de la imagen corrupta y reconstruida. Se experimenta con diferentes valores de p en el rango (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 16s - loss: 0.3133 - val_loss: 0.2685\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2663 - val_loss: 0.2652\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2646 - val_loss: 0.2643\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2639 - val_loss: 0.2638\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2636 - val_loss: 0.2635\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2633 - val_loss: 0.2633\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2631 - val_loss: 0.2631\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2629 - val_loss: 0.2630\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2627 - val_loss: 0.2628\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2625 - val_loss: 0.2625\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2623 - val_loss: 0.2622\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2619 - val_loss: 0.2618\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2613 - val_loss: 0.2611\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2605 - val_loss: 0.2600\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2592 - val_loss: 0.2585\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2575 - val_loss: 0.2567\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2557 - val_loss: 0.2549\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2538 - val_loss: 0.2531\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2522 - val_loss: 0.2516\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2508 - val_loss: 0.2503\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2496 - val_loss: 0.2492\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2484 - val_loss: 0.2480\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2473 - val_loss: 0.2469\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2461 - val_loss: 0.2456\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2447 - val_loss: 0.2442\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2432 - val_loss: 0.2426\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2416 - val_loss: 0.2409\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2398 - val_loss: 0.2391\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2380 - val_loss: 0.2372\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2362 - val_loss: 0.2355\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2344 - val_loss: 0.2337\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2327 - val_loss: 0.2320\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2311 - val_loss: 0.2304\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2295 - val_loss: 0.2289\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2281 - val_loss: 0.2275\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2267 - val_loss: 0.2262\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2255 - val_loss: 0.2250\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2243 - val_loss: 0.2239\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2232 - val_loss: 0.2229\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2222 - val_loss: 0.2219\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2213 - val_loss: 0.2210\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2204 - val_loss: 0.2202\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2196 - val_loss: 0.2195\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2189 - val_loss: 0.2187\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2182 - val_loss: 0.2181\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2176 - val_loss: 0.2175\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2170 - val_loss: 0.2169\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2164 - val_loss: 0.2164\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2158 - val_loss: 0.2158\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2153 - val_loss: 0.2154\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.3097 - val_loss: 0.2683\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2663 - val_loss: 0.2653\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2647 - val_loss: 0.2644\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2640 - val_loss: 0.2638\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2636 - val_loss: 0.2635\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2632 - val_loss: 0.2631\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2627 - val_loss: 0.2623\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2616 - val_loss: 0.2607\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2594 - val_loss: 0.2579\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2562 - val_loss: 0.2545\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2529 - val_loss: 0.2514\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2502 - val_loss: 0.2489\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2479 - val_loss: 0.2468\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2458 - val_loss: 0.2447\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2436 - val_loss: 0.2422\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2410 - val_loss: 0.2394\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2381 - val_loss: 0.2364\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2351 - val_loss: 0.2334\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2321 - val_loss: 0.2303\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2292 - val_loss: 0.2274\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2264 - val_loss: 0.2247\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2239 - val_loss: 0.2222\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2215 - val_loss: 0.2200\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2194 - val_loss: 0.2180\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2175 - val_loss: 0.2161\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2157 - val_loss: 0.2145\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2141 - val_loss: 0.2129\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2126 - val_loss: 0.2114\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2112 - val_loss: 0.2101\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2099 - val_loss: 0.2088\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2086 - val_loss: 0.2076\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2074 - val_loss: 0.2064\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2062 - val_loss: 0.2053\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 10s - loss: 0.2051 - val_loss: 0.2043\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2041 - val_loss: 0.2033\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2031 - val_loss: 0.2024\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2022 - val_loss: 0.2015\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2013 - val_loss: 0.2006\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2004 - val_loss: 0.1998\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1996 - val_loss: 0.1990\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1988 - val_loss: 0.1982\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1980 - val_loss: 0.1975\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1973 - val_loss: 0.1968\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1965 - val_loss: 0.1961\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1958 - val_loss: 0.1954\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1952 - val_loss: 0.1948\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1945 - val_loss: 0.1942\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1939 - val_loss: 0.1936\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1933 - val_loss: 0.1930\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1927 - val_loss: 0.1924\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.3032 - val_loss: 0.2676\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2660 - val_loss: 0.2651\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2645 - val_loss: 0.2643\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2640 - val_loss: 0.2638\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2636 - val_loss: 0.2635\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2632 - val_loss: 0.2627\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2616 - val_loss: 0.2603\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2585 - val_loss: 0.2566\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2549 - val_loss: 0.2533\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2519 - val_loss: 0.2505\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2493 - val_loss: 0.2479\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2465 - val_loss: 0.2448\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2430 - val_loss: 0.2408\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2386 - val_loss: 0.2359\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2336 - val_loss: 0.2308\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2289 - val_loss: 0.2262\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2245 - val_loss: 0.2221\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2207 - val_loss: 0.2186\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2174 - val_loss: 0.2155\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2145 - val_loss: 0.2127\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2119 - val_loss: 0.2102\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2095 - val_loss: 0.2080\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2073 - val_loss: 0.2059\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2053 - val_loss: 0.2040\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2035 - val_loss: 0.2022\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2018 - val_loss: 0.2006\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2002 - val_loss: 0.1991\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1987 - val_loss: 0.1977\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1973 - val_loss: 0.1964\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1960 - val_loss: 0.1952\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1948 - val_loss: 0.1940\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1936 - val_loss: 0.1929\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1924 - val_loss: 0.1918\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1913 - val_loss: 0.1907\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1903 - val_loss: 0.1897\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1892 - val_loss: 0.1887\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1883 - val_loss: 0.1878\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1873 - val_loss: 0.1869\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1865 - val_loss: 0.1861s: \n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1848 - val_loss: 0.1846\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1841 - val_loss: 0.1838\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1834 - val_loss: 0.1832\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1827 - val_loss: 0.1826\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1820 - val_loss: 0.1819\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1814 - val_loss: 0.1813\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1808 - val_loss: 0.1808\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1803 - val_loss: 0.1803\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1797 - val_loss: 0.1798\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1792 - val_loss: 0.1793\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2997 - val_loss: 0.2673\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2657 - val_loss: 0.2649\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2644 - val_loss: 0.2641\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2639 - val_loss: 0.2638\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2636 - val_loss: 0.2635\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2631 - val_loss: 0.2625\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2612 - val_loss: 0.2597\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2576 - val_loss: 0.2557\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2538 - val_loss: 0.2522\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2506 - val_loss: 0.2491\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2475 - val_loss: 0.2459\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2442 - val_loss: 0.2423\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2407 - val_loss: 0.2389\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2373 - val_loss: 0.2354\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2339 - val_loss: 0.2322\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2308 - val_loss: 0.2290\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 10s - loss: 0.2278 - val_loss: 0.2261\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2250 - val_loss: 0.2235\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2225 - val_loss: 0.2210\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2201 - val_loss: 0.2187\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2179 - val_loss: 0.2166\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2159 - val_loss: 0.2147\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2140 - val_loss: 0.2128\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2122 - val_loss: 0.2111\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2105 - val_loss: 0.2094\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2088 - val_loss: 0.2078\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2073 - val_loss: 0.2063\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2058 - val_loss: 0.2049\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2044 - val_loss: 0.2035\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2031 - val_loss: 0.2022\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2018 - val_loss: 0.2010\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2006 - val_loss: 0.1998\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1994 - val_loss: 0.1986\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1982 - val_loss: 0.1975\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1971 - val_loss: 0.1963\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1960 - val_loss: 0.1953\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1949 - val_loss: 0.1942\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1938 - val_loss: 0.1932\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1928 - val_loss: 0.1923\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1918 - val_loss: 0.1913\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1909 - val_loss: 0.1904\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1900 - val_loss: 0.1895\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1892 - val_loss: 0.1887\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1884 - val_loss: 0.1879\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1876 - val_loss: 0.1872\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1868 - val_loss: 0.1865\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1861 - val_loss: 0.1858\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1854 - val_loss: 0.1851\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1848 - val_loss: 0.1845\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1841 - val_loss: 0.1838\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2977 - val_loss: 0.2671\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2656 - val_loss: 0.2648\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2643 - val_loss: 0.2641\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2638 - val_loss: 0.2638\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2636 - val_loss: 0.2636\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2634 - val_loss: 0.2634\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2631 - val_loss: 0.2624\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2600 - val_loss: 0.2575\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2548 - val_loss: 0.2526\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2509 - val_loss: 0.2493\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2478 - val_loss: 0.2462\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2447 - val_loss: 0.2429\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2413 - val_loss: 0.2393\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2376 - val_loss: 0.2354\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2338 - val_loss: 0.2315\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2299 - val_loss: 0.2276\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2261 - val_loss: 0.2238\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2224 - val_loss: 0.2203\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2191 - val_loss: 0.2172\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2162 - val_loss: 0.2146\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2137 - val_loss: 0.2122\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2115 - val_loss: 0.2101\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2096 - val_loss: 0.2083\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2078 - val_loss: 0.2066\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2062 - val_loss: 0.2051\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2048 - val_loss: 0.2038\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2035 - val_loss: 0.2025\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2023 - val_loss: 0.2013\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2012 - val_loss: 0.2003\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2002 - val_loss: 0.1993\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1992 - val_loss: 0.1984\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1983 - val_loss: 0.1975\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1973 - val_loss: 0.1965\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1963 - val_loss: 0.1955\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1953 - val_loss: 0.1945\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1942 - val_loss: 0.1934\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1931 - val_loss: 0.1923\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1920 - val_loss: 0.1912\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1909 - val_loss: 0.1901\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1898 - val_loss: 0.1890\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1886 - val_loss: 0.1878\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1875 - val_loss: 0.1867\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1864 - val_loss: 0.1857\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1854 - val_loss: 0.1848\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1845 - val_loss: 0.1838\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1836 - val_loss: 0.1830\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1827 - val_loss: 0.1821\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1819 - val_loss: 0.1813\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1811 - val_loss: 0.1806\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1804 - val_loss: 0.1799\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 11s - loss: 0.2964 - val_loss: 0.2670\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2655 - val_loss: 0.2647\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2642 - val_loss: 0.2640\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2638 - val_loss: 0.2637\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2635 - val_loss: 0.2634\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2622 - val_loss: 0.2610\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2590 - val_loss: 0.2571\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2552 - val_loss: 0.2536\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2518 - val_loss: 0.2502\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2484 - val_loss: 0.2465\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2447 - val_loss: 0.2426\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2408 - val_loss: 0.2386\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2368 - val_loss: 0.2345\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2328 - val_loss: 0.2305\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2289 - val_loss: 0.2267\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2253 - val_loss: 0.2232\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2219 - val_loss: 0.2200\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2189 - val_loss: 0.2171\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2161 - val_loss: 0.2144\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2136 - val_loss: 0.2120\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2113 - val_loss: 0.2097\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2092 - val_loss: 0.2077\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2073 - val_loss: 0.2059\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2056 - val_loss: 0.2043\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2041 - val_loss: 0.2028\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2027 - val_loss: 0.2014\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2014 - val_loss: 0.2002\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2002 - val_loss: 0.1991\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1991 - val_loss: 0.1980\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1981 - val_loss: 0.1970\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1971 - val_loss: 0.1961\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1962 - val_loss: 0.1953\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1954 - val_loss: 0.1945\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1946 - val_loss: 0.1937\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1938 - val_loss: 0.1929\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1929 - val_loss: 0.1920\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1920 - val_loss: 0.1910\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1910 - val_loss: 0.1900\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1900 - val_loss: 0.1891\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1890 - val_loss: 0.1881\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1880 - val_loss: 0.1872\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1871 - val_loss: 0.1863\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1862 - val_loss: 0.1855\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1854 - val_loss: 0.1847\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1845 - val_loss: 0.1839\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1837 - val_loss: 0.1831\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1829 - val_loss: 0.1822\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1821 - val_loss: 0.1815\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1813 - val_loss: 0.1807\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1806 - val_loss: 0.1800\n"
     ]
    }
   ],
   "source": [
    "noise_levels = [0.1,0.2,0.4,0.6,0.8,1.0]\n",
    "i = 0\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    i += 1\n",
    "    noise_mask = binomial(n=1,p=noise_level,size=x_train.shape)\n",
    "    noisy_x_train = x_train*noise_mask\n",
    "    noise_mask = binomial(n=1,p=noise_level,size=x_val.shape)\n",
    "    noisy_x_val = x_val*noise_mask\n",
    "    noise_mask = binomial(n=1,p=noise_level,size=x_test.shape)\n",
    "    noisy_x_test = x_test*noise_mask\n",
    "\n",
    "    input_img = Input(shape=(784,))\n",
    "    encoded = Dense(32, activation='sigmoid')(input_img)\n",
    "    decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "    encoded_input = Input(shape=(32,))\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "    autoencoder.fit(noisy_x_train,x_train,nb_epoch=50,batch_size=25,shuffle=True, validation_data=(noisy_x_val, x_val))\n",
    "    autoencoder.save(\"entrenamientos/autoencoder\"+str(i)+\".h5\")\n",
    "    encoder.save(\"entrenamientos/encoder\"+str(i)+\".h5\")\n",
    "    decoder.save(\"entrenamientos/decoder\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***c)***  Análogamente a a), se procede a generar artificialmente una versión corrupta de las imágenes en MNIST utilizando el siguiente modelo de ruido (Gaussian noise): si $\\textbf{x} \\in \\mathbb{R}^d$ es una de las imágenes originales, la versión ruidosa $\\tilde{\\textbf{x}}$ se obtiene\n",
    "como $\\tilde{\\textbf{x}} = \\textbf{x} + \\xi$ donde $\\xi \\in \\mathbb{R}^d$ es un vector aleatorio con componentes $\\mathcal{N} (0,\\sigma^2)$ independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAABzCAYAAAAfb55ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIIYQwAPw/3qU9k2UB41YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x211240b29b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import standard_normal\n",
    "devst = 0.5\n",
    "noise_mask = devst*standard_normal(size=x_train.shape)\n",
    "noisy_x_train = x_train + noise_mask\n",
    "noise_mask = devst*standard_normal(size=x_val.shape)\n",
    "noisy_x_val = x_val + noise_mask\n",
    "noise_mask = devst*standard_normal(size=x_test.shape)\n",
    "noisy_x_test = x_test + noise_mask\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(noisy_x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***d)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.2264 - val_loss: 0.1785\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1654 - val_loss: 0.1544\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1474 - val_loss: 0.1417\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1372 - val_loss: 0.1345\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1319 - val_loss: 0.1311\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1292 - val_loss: 0.1294\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1276 - val_loss: 0.1280\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1266 - val_loss: 0.1272\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1259 - val_loss: 0.1267\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1254 - val_loss: 0.1265\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1251 - val_loss: 0.1263\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1249 - val_loss: 0.1262\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1247 - val_loss: 0.1259\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1258\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1258\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1258\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1257\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1254\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1255\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1255\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1254\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1254\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1253\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1252\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1252\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1251\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1252\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1251\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1250\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1252\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1250\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1249\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1251\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1250\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1249\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1249\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2270 - val_loss: 0.1793\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1655 - val_loss: 0.1539\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1466 - val_loss: 0.1410\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1365 - val_loss: 0.1341\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1315 - val_loss: 0.1310\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1290 - val_loss: 0.1292\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1275 - val_loss: 0.1282\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1266 - val_loss: 0.1277\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1261 - val_loss: 0.1272\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1257 - val_loss: 0.1271\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1254 - val_loss: 0.1267\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1252 - val_loss: 0.1268\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1251 - val_loss: 0.1266\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1249 - val_loss: 0.1265\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1248 - val_loss: 0.1263\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1247 - val_loss: 0.1263\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1263\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1263\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1262\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1262\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1261\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1260\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1261\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1259\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1258\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1259\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1258\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1258\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1258\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1260\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1258\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1258\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1257\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 11s - loss: 0.1240 - val_loss: 0.1259\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1240 - val_loss: 0.1257\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1256\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1257\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1257\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1257\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1256\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1256\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1255\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1256\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1257\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2288 - val_loss: 0.1818\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1675 - val_loss: 0.1553\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1476 - val_loss: 0.1417\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1372 - val_loss: 0.1348\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1321 - val_loss: 0.1315\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1293 - val_loss: 0.1297\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1277 - val_loss: 0.1285\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1268 - val_loss: 0.1280\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1262 - val_loss: 0.1274\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1257 - val_loss: 0.1272\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1254 - val_loss: 0.1268\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1252 - val_loss: 0.1267\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1250 - val_loss: 0.1267\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1248 - val_loss: 0.1265\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1247 - val_loss: 0.1266\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1265\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1263\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1263\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1263\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1261\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1260\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1261\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1261\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1260\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1258\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1258\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1260\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1259\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1259\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1259\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1259\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1257\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1257\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1258\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1257\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1255\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1254\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1254\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2295 - val_loss: 0.1804\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1666 - val_loss: 0.1551\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1478 - val_loss: 0.1416\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1374 - val_loss: 0.1347\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1321 - val_loss: 0.1310\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1293 - val_loss: 0.1292\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1277 - val_loss: 0.1283\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1268 - val_loss: 0.1276\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1261 - val_loss: 0.1270\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1256 - val_loss: 0.1266\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1253 - val_loss: 0.1266\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1251 - val_loss: 0.1262\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1249 - val_loss: 0.1262\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1248 - val_loss: 0.1261\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1247 - val_loss: 0.1261\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1259\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1260\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1258\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1259\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1257\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1258\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1260\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1257\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1255\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1256\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1256\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1254\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1255\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1255\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1254\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1255\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1254\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1254\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1254\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1254\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1253\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1255\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1254\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1254\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1252\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1252\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1252\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1253\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.2310 - val_loss: 0.1824\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1690 - val_loss: 0.1568\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1487 - val_loss: 0.1424\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1378 - val_loss: 0.1350\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1323 - val_loss: 0.1314\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1294 - val_loss: 0.1293\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1278 - val_loss: 0.1282\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1268 - val_loss: 0.1275\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1261 - val_loss: 0.1271\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1257 - val_loss: 0.1268\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1253 - val_loss: 0.1266\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1251 - val_loss: 0.1264\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1249 - val_loss: 0.1263\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1247 - val_loss: 0.1260\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1246 - val_loss: 0.1260\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1259\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1244 - val_loss: 0.1260\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1243 - val_loss: 0.1260\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1257\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1258\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1241 - val_loss: 0.1257\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1255\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1256\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1255\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1256\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1255\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1255\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1254\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1254\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1253\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1253\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1254\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1254\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1253\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1255\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1252\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1252\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1253\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1252\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1252\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1251\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1251\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1252\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 11s - loss: 0.2299 - val_loss: 0.1814\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1670 - val_loss: 0.1552\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1475 - val_loss: 0.1418\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1369 - val_loss: 0.1346\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 12s - loss: 0.1315 - val_loss: 0.1310\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 12s - loss: 0.1287 - val_loss: 0.1291\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 12s - loss: 0.1272 - val_loss: 0.1284\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1263 - val_loss: 0.1275\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1258 - val_loss: 0.1272\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1254 - val_loss: 0.1269\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1252 - val_loss: 0.1267\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1250 - val_loss: 0.1266\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1248 - val_loss: 0.1264\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1247 - val_loss: 0.1264\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1245 - val_loss: 0.1263\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1245 - val_loss: 0.1261\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1244 - val_loss: 0.1261\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1243 - val_loss: 0.1261\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1242 - val_loss: 0.1261\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1242 - val_loss: 0.1260\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1241 - val_loss: 0.1259\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1240 - val_loss: 0.1258\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1259\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1240 - val_loss: 0.1258\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1239 - val_loss: 0.1258\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1239 - val_loss: 0.1256\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1256\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1256\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1238 - val_loss: 0.1255\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1256\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1257\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1237 - val_loss: 0.1255\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 11s - loss: 0.1236 - val_loss: 0.1256\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1256\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1255\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1256\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1254\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1236 - val_loss: 0.1256\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1256\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1254\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1256\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1254\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1255\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1253\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1254\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1235 - val_loss: 0.1255\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 10s - loss: 0.1234 - val_loss: 0.1254\n"
     ]
    }
   ],
   "source": [
    "devsts = [0.1,0.3,0.5,0.7,0.9,1.0]\n",
    "i = 0\n",
    "\n",
    "for devsts in devsts:\n",
    "    i += 1\n",
    "    noise_mask = devst*standard_normal(size=x_train.shape)\n",
    "    noisy_x_train = x_train+noise_mask\n",
    "    noise_mask = devst*standard_normal(size=x_val.shape)\n",
    "    noisy_x_val = x_val+noise_mask\n",
    "    noise_mask = devst*standard_normal(size=x_test.shape)\n",
    "    noisy_x_test = x_test+noise_mask\n",
    "\n",
    "    input_img = Input(shape=(784,))\n",
    "    encoded = Dense(32, activation='relu')(input_img)\n",
    "    decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "    encoded_input = Input(shape=(32,))\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "    autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
    "    autoencoder.fit(noisy_x_train,x_train,nb_epoch=50,batch_size=25,shuffle=True, validation_data=(noisy_x_val, x_val))\n",
    "    autoencoder.save(\"entrenamientos/autoencoder_2_\"+str(i)+\".h5\")\n",
    "    encoder.save(\"entrenamientos/encoder_2_\"+str(i)+\".h5\")\n",
    "    decoder.save(\"entrenamientos/decoder_2_\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*** e)*** esta no la pude entender jaja. La dejo para el final para darle una vuelta con calma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
