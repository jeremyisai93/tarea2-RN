{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pre-entrenamiento\n",
    "\n",
    "En esta seccióon se utilizará un AE para pre-entrenar redes profundas. El efecto esperado es regularizar el modelo, posicionando el modelo de partida en una buena zona del espacio de parámetros. Se hace uso de las siguientes librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import binomial\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, load_model, save_model, Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga y pre-procesa el data set de igual manera que en la secciones _3.1_ y _3.2_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalizacion de imagenes\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Transformación en vectores R^{784}\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Creación conjunto de validación\n",
    "nval = 5000\n",
    "x_val = x_train[-nval:]\n",
    "y_val = y_train[-nval:]\n",
    "x_train = x_train[:-nval]\n",
    "y_train = y_train[:-nval]\n",
    "\n",
    "# Transformación de salidas a probabilidades de activación\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***a)*** Inicialmente se entrena una red FF para clasificar las imágenes de MNIST. Se emplea SGD básico con tasa de aprendizaje fija $\\eta = 1$ y 50 epochs. Se utiliza una arquitectura $784 \\times 1000 \\times 1000 \\times 10$ y funciones de activación sigmoidales. Se procede a determinar el error de clasificación alcanzado por el modelo en el conjunto de test, sin el empleo de pre-entrenamiento por medio de AE's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.1519 - acc: 0.9492 - val_loss: 0.0508 - val_acc: 0.9834\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0581 - acc: 0.9803 - val_loss: 0.0382 - val_acc: 0.9874\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0481 - acc: 0.9839 - val_loss: 0.0345 - val_acc: 0.9888\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0415 - acc: 0.9860 - val_loss: 0.0301 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0369 - acc: 0.9875 - val_loss: 0.0249 - val_acc: 0.9923\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0327 - acc: 0.9891 - val_loss: 0.0252 - val_acc: 0.9917\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0293 - acc: 0.9902 - val_loss: 0.0216 - val_acc: 0.9928\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0266 - acc: 0.9912 - val_loss: 0.0194 - val_acc: 0.9936\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0242 - acc: 0.9917 - val_loss: 0.0190 - val_acc: 0.9941\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0189 - val_acc: 0.9942\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0203 - acc: 0.9933 - val_loss: 0.0182 - val_acc: 0.9941\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0187 - acc: 0.9938 - val_loss: 0.0198 - val_acc: 0.9935\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0171 - val_acc: 0.9945\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0154 - val_acc: 0.9949\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0163 - val_acc: 0.9944\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0138 - val_acc: 0.9952\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0132 - acc: 0.9956 - val_loss: 0.0136 - val_acc: 0.9955\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0138 - val_acc: 0.9955\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0130 - val_acc: 0.9955\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0132 - val_acc: 0.9956\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0137 - val_acc: 0.9958\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0123 - val_acc: 0.9960\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0122 - val_acc: 0.9963\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0126 - val_acc: 0.9960\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0141 - val_acc: 0.9956\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0117 - val_acc: 0.9962\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0120 - val_acc: 0.9961\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0114 - val_acc: 0.9966\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9964\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0114 - val_acc: 0.9966\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0118 - val_acc: 0.9964\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0124 - val_acc: 0.9962\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0107 - val_acc: 0.9967\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0125 - val_acc: 0.9964\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0121 - val_acc: 0.9962\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0116 - val_acc: 0.9966\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0128 - val_acc: 0.9965\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0121 - val_acc: 0.9965\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0107 - val_acc: 0.9969\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0115 - val_acc: 0.9967\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0117 - val_acc: 0.9965\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0116 - val_acc: 0.9966\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0118 - val_acc: 0.9966\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0118 - val_acc: 0.9966\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0114 - val_acc: 0.9966\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0119 - val_acc: 0.9965\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0115 - val_acc: 0.9967\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0121 - val_acc: 0.9966\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 29s - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0114 - val_acc: 0.9967\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0122 - val_acc: 0.9966\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "\n",
    "n_hidden_layer1 = 1000\n",
    "activation_layer1 = 'sigmoid'\n",
    "decoder_activation_1 = 'sigmoid'\n",
    "n_hidden_layer2 = 1000\n",
    "activation_layer2 = 'sigmoid'\n",
    "decoder_activation_2 = 'sigmoid'\n",
    "loss_ = 'binary_crossentropy'\n",
    "optimizer_ = SGD(lr=1.0)\n",
    "epochs_ = 50\n",
    "batch_size_ = 25\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_layer1, activation=activation_layer1, input_shape=(784,)))\n",
    "model.add(Dense(n_hidden_layer2, activation=activation_layer2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizer_, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train, epochs=epochs_, batch_size=25,shuffle=True, validation_data=(x_val, Y_val), verbose=1)\n",
    "model.save('entrenamientos/SigmoidNet784x1000x1000x10-50epochs.h5')\n",
    "#TRAINING CAN THEN BE RESUMED FROM THIS POINT :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.01269852604996704\n",
      "Test accuracy: 0.9960399953842163\n",
      "Error de clasificacion en conjunto de test: 0.396000461578 %\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('entrenamientos/SigmoidNet784x1000x1000x10-50epochs.h5');\n",
    "model1.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "loss,acc = model1.evaluate(x_test, Y_test, verbose=0)\n",
    "print('Test loss: {0}'.format(loss)); print('Test accuracy: {0}'.format(acc))\n",
    "print ('Error de clasificacion en conjunto de test:', (1 - acc) * 100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se determina un error de clasificación alcanzado por el modelo en el conjunto de test igual a $0.396000461578\\%$. Resulta ser un error bastante competitivo, implicando un desafío considerable de superar (experimentación realizada en ítems posteriores) por modelos pre-entrenados con AE's.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***b)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 37s - loss: 0.2369 - val_loss: 0.1995\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1802 - val_loss: 0.1655\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1561 - val_loss: 0.1478\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1415 - val_loss: 0.1359\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1312 - val_loss: 0.1272\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1235 - val_loss: 0.1205\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1175 - val_loss: 0.1152\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1127 - val_loss: 0.1108\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1087 - val_loss: 0.1072\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1053 - val_loss: 0.1041\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1024 - val_loss: 0.1015\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1000 - val_loss: 0.0993\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0978 - val_loss: 0.0973\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0960 - val_loss: 0.0956\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0943 - val_loss: 0.0940\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0928 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0914 - val_loss: 0.0914\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0891 - val_loss: 0.0892\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0881 - val_loss: 0.0883\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0872 - val_loss: 0.0874\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0864 - val_loss: 0.0866\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0856 - val_loss: 0.0858\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0849 - val_loss: 0.0852\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0842 - val_loss: 0.0845\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0836 - val_loss: 0.0839\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0830 - val_loss: 0.0834\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0824 - val_loss: 0.0829\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0819 - val_loss: 0.0824\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0814 - val_loss: 0.0819\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0810 - val_loss: 0.0815\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0805 - val_loss: 0.0810\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0801 - val_loss: 0.0807\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0797 - val_loss: 0.0803\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0794 - val_loss: 0.0799\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0790 - val_loss: 0.0796\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0787 - val_loss: 0.0793\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0784 - val_loss: 0.0790\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0781 - val_loss: 0.0787\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0778 - val_loss: 0.0784\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0775 - val_loss: 0.0781\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0772 - val_loss: 0.0779\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0770 - val_loss: 0.0776\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0767 - val_loss: 0.0774\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0765 - val_loss: 0.0771\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0762 - val_loss: 0.0769\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0760 - val_loss: 0.0767\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0758 - val_loss: 0.0765\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0756 - val_loss: 0.0763\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0754 - val_loss: 0.0761\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.6676 - val_loss: 0.6462\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.6298 - val_loss: 0.6169\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.6081 - val_loss: 0.6005\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5948 - val_loss: 0.5899\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5859 - val_loss: 0.5827\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5797 - val_loss: 0.5776\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5753 - val_loss: 0.5739\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5722 - val_loss: 0.5713\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5698 - val_loss: 0.5692\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5680 - val_loss: 0.5676\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5666 - val_loss: 0.5664\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5654 - val_loss: 0.5654\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5645 - val_loss: 0.5645\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5638 - val_loss: 0.5638\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5631 - val_loss: 0.5633\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5626 - val_loss: 0.5628\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5622 - val_loss: 0.5624\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5618 - val_loss: 0.5620\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5614 - val_loss: 0.5617\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5611 - val_loss: 0.5614\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5609 - val_loss: 0.5612\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5606 - val_loss: 0.5609\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5604 - val_loss: 0.5607\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5602 - val_loss: 0.5605\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5600 - val_loss: 0.5603\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5598 - val_loss: 0.5602\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5597 - val_loss: 0.5600\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5595 - val_loss: 0.5599\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5594 - val_loss: 0.5597\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5592 - val_loss: 0.5596\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5591 - val_loss: 0.5595\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5590 - val_loss: 0.5594\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5589 - val_loss: 0.5593\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 30s - loss: 0.5588 - val_loss: 0.5592\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5587 - val_loss: 0.5591\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5586 - val_loss: 0.5590\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5585 - val_loss: 0.5589\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5584 - val_loss: 0.5588\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5584 - val_loss: 0.5588\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5583 - val_loss: 0.5587\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5582 - val_loss: 0.5586\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5582 - val_loss: 0.5586\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5581 - val_loss: 0.5585\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5580 - val_loss: 0.5584\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 33s - loss: 0.5580 - val_loss: 0.5584\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 32s - loss: 0.5579 - val_loss: 0.5583\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5579 - val_loss: 0.5583\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5578 - val_loss: 0.5582\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5578 - val_loss: 0.5582\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5577 - val_loss: 0.5581\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 34s - loss: 2.9078 - acc: 0.8182 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 32s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 32s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 31s - loss: 2.9167 - acc: 0.8180 - val_loss: 2.9124 - val_acc: 0.8183\n"
     ]
    }
   ],
   "source": [
    "## PARAMETERS\n",
    "n_hidden_layer1 = 1000\n",
    "activation_layer1 = 'sigmoid'; decoder_activation_1 = 'sigmoid'\n",
    "n_hidden_layer2 = 1000\n",
    "activation_layer2 = 'sigmoid'; decoder_activation_2 = 'sigmoid'\n",
    "loss_ = 'binary_crossentropy'\n",
    "optimizer_ = SGD(lr=1.0)\n",
    "epochs_ = 50\n",
    "batch_size_ = 25\n",
    "\n",
    "### AUTOENCODER 1\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(n_hidden_layer1, activation=activation_layer1)(input_img1)\n",
    "decoded1 = Dense(784, activation=decoder_activation_1)(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder1.fit(x_train, x_train, epochs=epochs_, batch_size=batch_size_, \n",
    "                 shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('entrenamientos/3_3/Sigmoid_autoencoder_layer1_ae.h5')\n",
    "encoder1.save('entrenamientos/3_3/Sigmoid_encoder_layer1_ae.h5')\n",
    "\n",
    "### AUTOENCODER 2\n",
    "# FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "x_train_encoded1 = encoder1.predict(x_train) \n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(n_hidden_layer1,))\n",
    "encoded2 = Dense(n_hidden_layer2, activation=activation_layer2)(input_img2)\n",
    "decoded2 = Dense(n_hidden_layer1, activation=decoder_activation_2)(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder2.fit(x_train_encoded1, x_train_encoded1, epochs=epochs_, batch_size=batch_size_,\n",
    "                 shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "encoded_input2 = Input(shape=(n_hidden_layer2,))\n",
    "autoencoder2.save('entrenamientos/3_3/Sigmoid_autoencoder_layer2_ae.h5')\n",
    "encoder2.save('entrenamientos/3_3/Sigmoid_encoder_layer2_ae.h5')\n",
    "\n",
    "### FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add( Dense(n_hidden_layer1, activation=activation_layer1, input_shape=(784,)) )\n",
    "model.layers[-1].set_weights( autoencoder1.layers[1].get_weights() )\n",
    "model.add( Dense(n_hidden_layer2, activation=activation_layer2) )\n",
    "model.layers[-1].set_weights( autoencoder2.layers[1].get_weights() )\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=optimizer_, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train, epochs=20, batch_size=25, shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('entrenamientos/3_3/Sigmoid_784x1000x1000x10_finetunning_ae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***c)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(X_train, X_val, X_test, devst=0.1):\n",
    "    noise_mask = devst*np.random.standard_normal(size=X_train.shape)\n",
    "    X_train_noisy = X_train + noise_mask\n",
    "    noise_mask = devst*np.random.standard_normal(size=X_val.shape)\n",
    "    X_val_noisy = X_val + noise_mask\n",
    "    noise_mask = devst*np.random.standard_normal(size=X_test.shape)\n",
    "    X_test_noisy = X_test + noise_mask\n",
    "    return X_train_noisy, X_val_noisy, X_test_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.2371 - val_loss: 0.1999\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.1805 - val_loss: 0.1658\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1565 - val_loss: 0.1483\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1421 - val_loss: 0.1366\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1320 - val_loss: 0.1280\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1245 - val_loss: 0.1215\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1185 - val_loss: 0.1162\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1137 - val_loss: 0.1119\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1098 - val_loss: 0.1083\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1065 - val_loss: 0.1053\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1036 - val_loss: 0.1028\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.1012 - val_loss: 0.1006\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0991 - val_loss: 0.0986\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0972 - val_loss: 0.0969\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0956 - val_loss: 0.0954\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0928 - val_loss: 0.0928\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0905 - val_loss: 0.0906\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0895 - val_loss: 0.0897\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0886 - val_loss: 0.0889\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 26s - loss: 0.0878 - val_loss: 0.0881\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0870 - val_loss: 0.0873\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0863 - val_loss: 0.0867\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0856 - val_loss: 0.0860\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0850 - val_loss: 0.0855\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0844 - val_loss: 0.0849\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0839 - val_loss: 0.0844\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0834 - val_loss: 0.0839\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0829 - val_loss: 0.0835\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0825 - val_loss: 0.0831\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0821 - val_loss: 0.0826\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0817 - val_loss: 0.0823\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0813 - val_loss: 0.0819\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0809 - val_loss: 0.0816\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0806 - val_loss: 0.0812\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0803 - val_loss: 0.0809\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0800 - val_loss: 0.0806\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 27s - loss: 0.0797 - val_loss: 0.0804\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0794 - val_loss: 0.0801\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 28s - loss: 0.0791 - val_loss: 0.0798\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0788 - val_loss: 0.0796\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0786 - val_loss: 0.0793\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0784 - val_loss: 0.0791\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0781 - val_loss: 0.0789\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.0779 - val_loss: 0.0787\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0777 - val_loss: 0.0785\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0775 - val_loss: 0.0783\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0773 - val_loss: 0.0781\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.0771 - val_loss: 0.0779\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 57s - loss: 0.6670 - val_loss: 0.6454\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.6291 - val_loss: 0.6164\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.6079 - val_loss: 0.6004\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5949 - val_loss: 0.5901\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5863 - val_loss: 0.5832\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5804 - val_loss: 0.5783\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5762 - val_loss: 0.5748\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5731 - val_loss: 0.5722\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5708 - val_loss: 0.5703\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5691 - val_loss: 0.5687\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5677 - val_loss: 0.5675\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5666 - val_loss: 0.5665\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5657 - val_loss: 0.5657\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5650 - val_loss: 0.5651\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5644 - val_loss: 0.5645\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5639 - val_loss: 0.5640\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5634 - val_loss: 0.5636\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5630 - val_loss: 0.5633\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5627 - val_loss: 0.5630\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5624 - val_loss: 0.5627\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5621 - val_loss: 0.5624\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5619 - val_loss: 0.5622\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5617 - val_loss: 0.5620\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5615 - val_loss: 0.5618\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5613 - val_loss: 0.5617\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5612 - val_loss: 0.5615\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5610 - val_loss: 0.5614\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5609 - val_loss: 0.5612\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5607 - val_loss: 0.5611\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5606 - val_loss: 0.5610\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5605 - val_loss: 0.5609\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5604 - val_loss: 0.5608\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5603 - val_loss: 0.5607\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 31s - loss: 0.5602 - val_loss: 0.5606\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5601 - val_loss: 0.5605\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5600 - val_loss: 0.5604\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 30s - loss: 0.5599 - val_loss: 0.5603\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5599 - val_loss: 0.5603\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5598 - val_loss: 0.5602\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5597 - val_loss: 0.5601\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5597 - val_loss: 0.5601\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5596 - val_loss: 0.5600\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5595 - val_loss: 0.5599\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5595 - val_loss: 0.5599\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5594 - val_loss: 0.5598\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5594 - val_loss: 0.5598\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5593 - val_loss: 0.5597\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5593 - val_loss: 0.5597\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5592 - val_loss: 0.5596\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 31s - loss: 0.5592 - val_loss: 0.5596\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 220s - loss: 2.8729 - acc: 0.8205 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 30s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 29s - loss: 2.8783 - acc: 0.8204 - val_loss: 2.8797 - val_acc: 0.8204\n"
     ]
    }
   ],
   "source": [
    "## PARAMETERS\n",
    "n_hidden_layer1 = 1000\n",
    "activation_layer1 = 'sigmoid'; decoder_activation_1 = 'sigmoid'\n",
    "n_hidden_layer2 = 1000\n",
    "activation_layer2 = 'sigmoid'; decoder_activation_2 = 'sigmoid'\n",
    "loss_ = 'binary_crossentropy'\n",
    "optimizer_ = SGD(lr=1.0)\n",
    "epochs_ = 50\n",
    "batch_size_ = 25\n",
    "\n",
    "# Data with gaussian noise\n",
    "x_train_noisy, x_val_noisy, x_test_noisy = gaussian_noise(x_train, x_val, x_test)\n",
    "\n",
    "### DENOISING AUTOENCODER 1\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(n_hidden_layer1, activation=activation_layer1)(input_img1)\n",
    "decoded1 = Dense(784, activation=decoder_activation_1)(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder1.fit(x_train_noisy, x_train, epochs=epochs_, batch_size=batch_size_, \n",
    "                 shuffle=True, validation_data=(x_val_noisy, x_val))\n",
    "autoencoder1.save('entrenamientos/3_3/Sigmoid_autoencoder_layer1_dae.h5')\n",
    "encoder1.save('entrenamientos/3_3/Sigmoid_encoder_layer1_dae.h5')\n",
    "\n",
    "### DENOISING AUTOENCODER 2\n",
    "# FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "x_train_encoded1 = encoder1.predict(x_train) \n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "# adding gaussian noise also to encoded data\n",
    "x_train_noisy_encoded1, x_val_noisy_encoded1, x_test_noisy_encoded1 = gaussian_noise(x_train_encoded1, x_val_encoded1,\n",
    "                                                                                     x_test_encoded1)\n",
    "input_img2 = Input(shape=(n_hidden_layer1,))\n",
    "encoded2 = Dense(n_hidden_layer2, activation=activation_layer2)(input_img2)\n",
    "decoded2 = Dense(n_hidden_layer1, activation=decoder_activation_2)(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder2.fit(x_train_noisy_encoded1, x_train_encoded1, epochs=epochs_, batch_size=batch_size_,\n",
    "                 shuffle=True, validation_data=(x_val_noisy_encoded1, x_val_encoded1))\n",
    "encoded_input2 = Input(shape=(n_hidden_layer2,))\n",
    "autoencoder2.save('entrenamientos/3_3/Sigmoid_autoencoder_layer2_dae.h5')\n",
    "encoder2.save('entrenamientos/3_3/Sigmoid_encoder_layer2_dae.h5')\n",
    "\n",
    "### FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add( Dense(n_hidden_layer1, activation=activation_layer1, input_shape=(784,)) )\n",
    "model.layers[-1].set_weights( autoencoder1.layers[1].get_weights() )\n",
    "model.add( Dense(n_hidden_layer2, activation=activation_layer2) )\n",
    "model.layers[-1].set_weights( autoencoder2.layers[1].get_weights() )\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=optimizer_, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train, epochs=20, batch_size=25, shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('entrenamientos/3_3/Sigmoid_784x1000x1000x10_finetunning_dae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***d)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_i) Función de activación ReLu:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "53375/55000 [============================>.] - ETA: 1s - loss: 0.1763"
     ]
    }
   ],
   "source": [
    "## PARAMETERS\n",
    "n_hidden_layer1 = 1000\n",
    "activation_layer1 = 'relu'; decoder_activation_1 = 'sigmoid'\n",
    "n_hidden_layer2 = 1000\n",
    "activation_layer2 = 'relu'; decoder_activation_2 = 'sigmoid'\n",
    "loss_ = 'binary_crossentropy'\n",
    "optimizer_ = SGD(lr=1.0)\n",
    "epochs_ = 50\n",
    "batch_size_ = 25\n",
    "\n",
    "### AUTOENCODER 1\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(n_hidden_layer1, activation=activation_layer1)(input_img1)\n",
    "decoded1 = Dense(784, activation=decoder_activation_1)(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder1.fit(x_train, x_train, epochs=epochs_, batch_size=batch_size_, \n",
    "                 shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('entrenamientos/3_3/Relu_autoencoder_layer1_ae.h5')\n",
    "encoder1.save('entrenamientos/3_3/Relu_encoder_layer1_ae.h5')\n",
    "\n",
    "### AUTOENCODER 2\n",
    "# FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "x_train_encoded1 = encoder1.predict(x_train) \n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(n_hidden_layer1,))\n",
    "encoded2 = Dense(n_hidden_layer2, activation=activation_layer2)(input_img2)\n",
    "decoded2 = Dense(n_hidden_layer1, activation=decoder_activation_2)(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder2.fit(x_train_encoded1, x_train_encoded1, epochs=epochs_, batch_size=batch_size_,\n",
    "                 shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "encoded_input2 = Input(shape=(n_hidden_layer2,))\n",
    "autoencoder2.save('entrenamientos/3_3/Relu_autoencoder_layer2_ae.h5')\n",
    "encoder2.save('entrenamientos/3_3/Relu_encoder_layer2_ae.h5')\n",
    "\n",
    "### FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add( Dense(n_hidden_layer1, activation=activation_layer1, input_shape=(784,)) )\n",
    "model.layers[-1].set_weights( autoencoder1.layers[1].get_weights() )\n",
    "model.add( Dense(n_hidden_layer2, activation=activation_layer2) )\n",
    "model.layers[-1].set_weights( autoencoder2.layers[1].get_weights() )\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=optimizer_, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train, epochs=20, batch_size=25, shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('entrenamientos/3_3/Relu_784x1000x1000x10_finetunning_ae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ii) Función de activación Tanh:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PARAMETERS\n",
    "n_hidden_layer1 = 1000\n",
    "activation_layer1 = 'tanh'; decoder_activation_1 = 'sigmoid'\n",
    "n_hidden_layer2 = 1000\n",
    "activation_layer2 = 'tanh'; decoder_activation_2 = 'sigmoid'\n",
    "loss_ = 'binary_crossentropy'\n",
    "optimizer_ = SGD(lr=1.0)\n",
    "epochs_ = 50\n",
    "batch_size_ = 25\n",
    "\n",
    "### AUTOENCODER 1\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(n_hidden_layer1, activation=activation_layer1)(input_img1)\n",
    "decoded1 = Dense(784, activation=decoder_activation_1)(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder1.fit(x_train, x_train, epochs=epochs_, batch_size=batch_size_, \n",
    "                 shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('entrenamientos/3_3/Tanh_autoencoder_layer1_ae.h5')\n",
    "encoder1.save('entrenamientos/3_3/Tanh_encoder_layer1_ae.h5')\n",
    "\n",
    "### AUTOENCODER 2\n",
    "# FORWARD PASS DATA THROUGH FIRST ENCODER\n",
    "x_train_encoded1 = encoder1.predict(x_train) \n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(n_hidden_layer1,))\n",
    "encoded2 = Dense(n_hidden_layer2, activation=activation_layer2)(input_img2)\n",
    "decoded2 = Dense(n_hidden_layer1, activation=decoder_activation_2)(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=optimizer_, loss=loss_)\n",
    "autoencoder2.fit(x_train_encoded1, x_train_encoded1, epochs=epochs_, batch_size=batch_size_,\n",
    "                 shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "encoded_input2 = Input(shape=(n_hidden_layer2,))\n",
    "autoencoder2.save('entrenamientos/3_3/Tanh_autoencoder_layer2_ae.h5')\n",
    "encoder2.save('entrenamientos/3_3/Tanh_encoder_layer2_ae.h5')\n",
    "\n",
    "### FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add( Dense(n_hidden_layer1, activation=activation_layer1, input_shape=(784,)) )\n",
    "model.layers[-1].set_weights( autoencoder1.layers[1].get_weights() )\n",
    "model.add( Dense(n_hidden_layer2, activation=activation_layer2) )\n",
    "model.layers[-1].set_weights( autoencoder2.layers[1].get_weights() )\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=optimizer_, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train, epochs=20, batch_size=25, shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('entrenamientos/3_3/Tanh_784x1000x1000x10_finetunning_ae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
